{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AlbertTokenizerFast, AutoModelForSequenceClassification, DistilBertTokenizerFast\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n  I tested the AA size Amazon brand battery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n  I've been buying AA and AAA batteries from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n  Don't buy these.  I did save a bunch of $'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n  I loved these batteries when  I first star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n  I read a lot of reviews and convinced myse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text\n",
       "0       5  \\n  I tested the AA size Amazon brand battery ...\n",
       "1       1  \\n  I've been buying AA and AAA batteries from...\n",
       "2       1  \\n  Don't buy these.  I did save a bunch of $'...\n",
       "3       1  \\n  I loved these batteries when  I first star...\n",
       "4       1  \\n  I read a lot of reviews and convinced myse..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('amazon_reviews.csv', index_col=0)\n",
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rating', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='rating', data=reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "rows_to_drop = np.random.choice(reviews_df[reviews_df['rating'] == 5].index, 17000, False)\n",
    "#rows_to_drop1 = np.random.choice(reviews_df[reviews_df['rating'] == 5].index, 20000, False)\n",
    "#rows_to_drop2 = np.random.choice(reviews_df[reviews_df['rating'] == 1].index, 3000, False)\n",
    "#rows_to_drop3 = np.random.choice(reviews_df[reviews_df['rating'] == 4].index, 1500, False)\n",
    "\n",
    "#rows_to_drop = np.concatenate([rows_to_drop1, rows_to_drop2, rows_to_drop3])\n",
    "reviews_df.drop(rows_to_drop, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rating', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='rating', data=reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del t\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.15, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.15, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#bert-base-uncased\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "config.hidden_dropout_prob = 0.15\n",
    "config.num_labels = 5\n",
    "config.output_attentions = False\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "\n",
    "t = AutoModelForSequenceClassification.from_pretrained(model_name, config=config).cuda()\n",
    "\n",
    "\n",
    "#for parameter in t.albert.parameters():\n",
    "#    parameter.requires_grad = False\n",
    "    \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df['text'], reviews_df['rating'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, texts, ratings):\n",
    "        \n",
    "        tokens = tokenizer(\n",
    "            text=texts.tolist(), \n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "        self.text = tokens['input_ids']\n",
    "        self.attention_mask = tokens['attention_mask']\n",
    "        self.ratings = ratings.reset_index().drop('index', axis=1)\n",
    "        self.ratings = self.ratings-1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {'input_ids': self.text[idx], 'attention_mask':self.attention_mask[idx], 'labels': self.ratings.iloc[idx] }\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ratings.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "test_ds = ReviewsDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    softmax = torch.nn.Softmax(dim=1)(torch.Tensor(logits))\n",
    "    predictions = torch.max(softmax, dim=1)\n",
    "    \n",
    "    return {'accuracy': accuracy_score(y_true=labels.reshape(-1), y_pred=predictions[1])}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"transformer_checkpoints\", \n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    logging_strategy='epoch',\n",
    "    dataloader_pin_memory=True, \n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=4.0,\n",
    "    per_device_eval_batch_size=8,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_accuracy',\n",
    "    learning_rate=3e-5,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=300\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t, \n",
    "    args=training_args, \n",
    "    train_dataset=train_ds, \n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10528' max='10528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10528/10528 1:57:46, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.007700</td>\n",
       "      <td>0.825294</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>133.978400</td>\n",
       "      <td>39.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.766249</td>\n",
       "      <td>0.724302</td>\n",
       "      <td>133.965000</td>\n",
       "      <td>39.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.930511</td>\n",
       "      <td>0.733612</td>\n",
       "      <td>134.046000</td>\n",
       "      <td>39.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>1.155779</td>\n",
       "      <td>0.738552</td>\n",
       "      <td>133.830300</td>\n",
       "      <td>39.326000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10528, training_loss=0.5979328271465824, metrics={'train_runtime': 7066.9341, 'train_samples_per_second': 1.49, 'total_flos': 2.8319933512704e+16, 'epoch': 4.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2632' max='2632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2632/2632 08:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20840643346309662,\n",
       " 'eval_accuracy': 0.9422802850356294,\n",
       " 'eval_runtime': 531.7871,\n",
       " 'eval_samples_per_second': 39.584,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "trainer.save_model('albert_base_uncased_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}